import argparse
import cv2
import numpy as np
import os
import torch
import tqdm

from basicsr.archs.colorformer_arch import ColorFormer as models
from basicsr.utils.img_util import tensor_lab2rgb
from basicsr.data.val_dataset import ValDataset
from queue import Queue
import _thread

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

write_buffer = Queue(maxsize=500)


def clear_write_buffer(args, write_buffer):
    while True:
        item = write_buffer.get()
        for name in item.keys():
            cls, filename = os.path.split(name)
            if cls:
                os.makedirs(os.path.join(args.output, cls), exist_ok=True)
            cv2.imwrite(os.path.join(args.output, name), item[name])


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--model_path',
        type=str,
        default=  # noqa: E251
        'pretrain/net_g_200000.pth'  # noqa: E501
    )
    parser.add_argument('--input', type=str, default='figure/', help='input test image folder or video path')
    parser.add_argument('--output', type=str, default='results', help='output folder or video path')
    parser.add_argument('--input_size', type=int, default=256, help='input size')
    args = parser.parse_args()

    # set up model
    model = models(
        'GLHTransformer',
        pretrained_path='pretrain/GLH.pth',
        input_size=[args.input_size, args.input_size],
        num_output_channels=2,
        last_norm='Spectral',
        do_normalize=False,
        color_centers_path='pretrain/color_embed_10000.npy',
        semantic_centers_path='pretrain/semantic_embed_10000.npy')
    model.load_state_dict(torch.load(args.model_path)['params'], strict=True)
    model.eval()
    model = model.to(device)
    os.makedirs(args.output, exist_ok=True)
    dataset = ValDataset(args.input, args.input_size, False)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=False, num_workers=8, drop_last=False)

    _thread.start_new_thread(clear_write_buffer, (args, write_buffer))
    with torch.no_grad():
        for (imgs, img_l, names) in tqdm.tqdm(dataloader):
            imgs = imgs.to(device)
            img_l = img_l.to(device)
            outs = model(imgs)
            outs = torch.cat([img_l, outs], dim=1)
            outs = tensor_lab2rgb(outs)
            outs = outs.cpu()
            for i in range(len(names)):
                output = outs[i].data.float().clamp_(0, 1).numpy()
                output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))
                output_img = (output * 255.0).round().astype(np.uint8)
                write_buffer.put({names[i]: output_img})
    import time
    while (not write_buffer.empty()):
        time.sleep(0.1)


if __name__ == '__main__':
    main()
